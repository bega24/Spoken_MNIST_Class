{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "# <p style=\"text-align: center;\">Lab 4 - Classification avec le dataset MNIST Spoken</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce laboratoire nous allons utiliser un réseau de neurones pour classifier les signaux audios des chiffres 0 à 9 prononcés par des humains. Pour ce faire, nous allons utiliser plusieurs types de données différents pour notre réseau de neurones.\n",
    "\n",
    "Tout d'abord nous testerons avec les signaux, puis avec le coefficients MFCC, et enfin nous utiliserons les Spectrogrammes. Nous analyserons les résultats pour les différentes approches utilisées.\n",
    "\n",
    "Concernant la méthodologie nous utiliserons le dataset \"spoken_mnist\" composée de 3000 données. Nous utiliserons 20% du dataset pour le test et 80% pour l'entrainement. Nous utiliserons un réseau fully-connected implémenté avec Pytorch ainsi que la fonction de perte d'entropie croisée. Nous utiliserons également 3 réseaux de neurones à une couche cachée avec chacun une couche d'entrée correspondant au types de données utilisées.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des bibliothèques nécessaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import copy\n",
    "import hub\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération de la base de données Spoken_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/spoken_mnist\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/spoken_mnist loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = hub.load(\"hub://activeloop/spoken_mnist\")\n",
    "\n",
    "# check out the first spectrogram, it's label, and who spoke it!\n",
    "plt.imshow(ds.spectrograms[0].numpy())\n",
    "plt.title(f\"{ds.speakers[0].data()}_{ds.labels[0].numpy()}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement des données\n",
    "\n",
    "#### Utilisation des fichiers audios\n",
    "\n",
    "Les fichiers audios ne sont pas tous de la même longueur. La moyenne de taille de nos fichiers audio est environ de 3500 nous allons donc mettre tous nos vecteur audios à une longueur de 3500 en prenant les 3500 premières valeurs pour les fichiers audios dont la longueur est supérieur et en complétant le tableau avec des zéros quand la longueur est inférieur à 3500.\n",
    "\n",
    "Ainsi nous obtenons 3000 vecteurs audios de 3500 éléments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 3000/3000"
     ]
    }
   ],
   "source": [
    "#l'éxécution de cette cellule peut prendre environ 2-3 min\n",
    "duree_audio = 3500 #longueur choisie pour chaque vecteur audio\n",
    "audio_data = []\n",
    "for i, sample in enumerate(ds):\n",
    "    a = (ds.audio[i][:duree_audio].numpy())\n",
    "    current_audio = np.concatenate(a, axis=0)\n",
    "    audio_data.append(current_audio)\n",
    "    print(f\"\\rItération {i+1}/{3000}\", end=\"\", flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajout de zéros pour remplir chaque vecteurs à la longueur choisie \n",
    "for i, sample in enumerate(ds):\n",
    "    if len(audio_data[i]) < duree_audio:\n",
    "        audio_data[i] = np.pad(audio_data[i], (0, duree_audio-len(audio_data[i])), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisation des MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette approche on calcul les MFCC de chaque audio. On choisi le nombre de 20 coefficient puis on fait la moyenne pour chaque audio. On se retrouve ainsi avec un vecteur de 20 coefficients pour chaque audio. On ajoute chaque vecteur de moyenne de coefficient au tenseur mfcc_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 3000/3000"
     ]
    }
   ],
   "source": [
    "mfcc_data = []\n",
    "j = 0\n",
    "for j, sample in enumerate(ds):\n",
    "    signal = audio_data[j]\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=signal, sr=44100, n_mfcc=20).T, axis=0)\n",
    "    mfcc_data.append(mfccs)\n",
    "    print(f\"\\rItération {j+1}/{3000}\", end=\"\", flush=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisation des spectrogramme\n",
    "\n",
    "On extrait chaque spectrogramme de notre ensemble de donnée. Ils sont sous la forme d'un tenseur de taille 64x64x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 3000/3000"
     ]
    }
   ],
   "source": [
    "spect_data = []\n",
    "for h, sample in enumerate(ds):\n",
    "    spect_data.append(ds.spectrograms[h].numpy())\n",
    "    print(f\"\\rItération {h+1}/{3000}\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalisation de la création des datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette parties nous allons extraire les labels les ajouter dans nos 3 datasets : audio_data, mfcc_data, spect_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait les labels de notre ensemble de données et on les mets dans un tenseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = []\n",
    "for j, sample in enumerate(ds):\n",
    "    label_data.append(float(ds.labels[j].numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créer nos 3 ensembles de données où chaque vecteur audio, mfcc ou spectrogramme  est associé au label correspondant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset = list(zip(audio_data, label_data))\n",
    "mfcc_dataset = list(zip(mfcc_data, label_data))\n",
    "spect_dataset = list(zip(spect_data, label_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va à présent mélanger les datasets afin d'extraire des ensembles de test et d'entrainement qui sont représentatifs de toutes nos classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffleDataset(datasets):\n",
    "    \n",
    "    \n",
    "    indices = list(range(len(datasets)))\n",
    "\n",
    "    \n",
    "    random.shuffle(indices)\n",
    "\n",
    "    dataset_shuffle = []\n",
    "\n",
    "    for idx in indices:\n",
    "        images, label = datasets[idx]\n",
    "        dataset_shuffle.append(datasets[idx])\n",
    "    \n",
    "    return dataset_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mélange des 3 datasets\n",
    "dataset_shuffle_audio = shuffleDataset(audio_dataset)\n",
    "dataset_shuffle_mfcc = shuffleDataset(mfcc_dataset)\n",
    "dataset_shuffle_spect = shuffleDataset(spect_dataset)\n",
    "\n",
    "#datasets entrainements et tests audios\n",
    "dataset_train_audio = dataset_shuffle_audio[:2400]\n",
    "dataset_test_audio = dataset_shuffle_audio[2400:]\n",
    "\n",
    "#datasets entrainements et tests mfcc\n",
    "dataset_train_mfcc = dataset_shuffle_mfcc[:2400]\n",
    "dataset_test_mfcc = dataset_shuffle_mfcc[2400:]\n",
    "\n",
    "#datasets entrainements et tests spectrogrammes\n",
    "dataset_train_spect = dataset_shuffle_spect[:2400]\n",
    "dataset_test_spect = dataset_shuffle_spect[2400:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge nos 6 datasets avec dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio\n",
    "dataloader_train_audio = torch.utils.data.DataLoader(dataset_train_audio, batch_size=25, shuffle=True)\n",
    "dataloader_test_audio = torch.utils.data.DataLoader(dataset_test_audio, batch_size=1, shuffle=True)\n",
    "\n",
    "#mfcc\n",
    "dataloader_train_mfcc = torch.utils.data.DataLoader(dataset_train_mfcc, batch_size=25, shuffle=True)\n",
    "dataloader_test_mfcc = torch.utils.data.DataLoader(dataset_test_mfcc, batch_size=1, shuffle=True)\n",
    "\n",
    "#spectrogramme\n",
    "dataloader_train_spect = torch.utils.data.DataLoader(dataset_train_spect, batch_size=25, shuffle=True)\n",
    "dataloader_test_spect = torch.utils.data.DataLoader(dataset_test_spect, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit le GPU pour entrainer notre réseau pour avoir une meilleure puissance de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choix du GPU si il est disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des 3 réseaux de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètres des réseaux\n",
    "\n",
    "On définit les paramètres communs de nos 3 réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper-paramètre du réseau \n",
    "num_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#loss utilisé\n",
    "criterion = nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créer une fonction qui nous permets de créer un réseau qui prend en entrée un vecteur avec la taille de notre choix. Cela nous permettra de facilement adapter notre réseau pour chaque type de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_nn(input_size):\n",
    "    class SimpleNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SimpleNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, 1000)\n",
    "            self.fc2 = nn.Linear(1000, 500)\n",
    "            self.fc3 = nn.Linear(500, 10)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "        \n",
    "    model = SimpleNN().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "\n",
    "    return model, optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous on implémente 3 réseaux, un pour chaque approche car ils n'ont pas la même couche d'entrée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_audio = 3500\n",
    "input_size_mfcc = 20\n",
    "input_size_spect = 64*64*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_audio, optimizer_audio = creation_nn(input_size_audio)\n",
    "model_mfcc, optimizer_mfcc = creation_nn(input_size_mfcc)\n",
    "model_spect, optimizer_spect = creation_nn(input_size_spect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boucles d'entrainements "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de la boucle d'entrainement\n",
    "\n",
    "On créer une fonction qui nous permet d'entrainer nos réseaux avec chaque types de données choisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrainement(dataset, input_size, model, optimizer):\n",
    "    #entrainement du model\n",
    "    n_total_steps = len(dataset)\n",
    "    loss_value = [] \n",
    "    iteration = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(dataset):  \n",
    "            images = images.float()\n",
    "            images = images.reshape(-1, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            #propagation avant\n",
    "            outputs = model(images)\n",
    "            labels = labels.squeeze()\n",
    "            labels = labels.long()\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            #rétropopagation et optimisation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            if (i+1) % 96 == 0:\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "                loss_value.append(loss.item())\n",
    "                iteration.append(((epoch+1)*n_total_steps)-n_total_steps+i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement avec données audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [96/96], Loss: 167.0843\n",
      "Epoch [2/50], Step [96/96], Loss: 10.5887\n",
      "Epoch [3/50], Step [96/96], Loss: 4.6661\n",
      "Epoch [4/50], Step [96/96], Loss: 0.0190\n",
      "Epoch [5/50], Step [96/96], Loss: 0.0090\n",
      "Epoch [6/50], Step [96/96], Loss: 0.0013\n",
      "Epoch [7/50], Step [96/96], Loss: 0.0561\n",
      "Epoch [8/50], Step [96/96], Loss: 0.0865\n",
      "Epoch [9/50], Step [96/96], Loss: 0.8806\n",
      "Epoch [10/50], Step [96/96], Loss: 0.0671\n",
      "Epoch [11/50], Step [96/96], Loss: 0.1063\n",
      "Epoch [12/50], Step [96/96], Loss: 1.4182\n",
      "Epoch [13/50], Step [96/96], Loss: 10.2565\n",
      "Epoch [14/50], Step [96/96], Loss: 1.9492\n",
      "Epoch [15/50], Step [96/96], Loss: 4.1701\n",
      "Epoch [16/50], Step [96/96], Loss: 3.0910\n",
      "Epoch [17/50], Step [96/96], Loss: 0.4367\n",
      "Epoch [18/50], Step [96/96], Loss: 0.0022\n",
      "Epoch [19/50], Step [96/96], Loss: 0.0008\n",
      "Epoch [20/50], Step [96/96], Loss: 0.0035\n",
      "Epoch [21/50], Step [96/96], Loss: 0.0014\n",
      "Epoch [22/50], Step [96/96], Loss: 0.0001\n",
      "Epoch [23/50], Step [96/96], Loss: 0.0105\n",
      "Epoch [24/50], Step [96/96], Loss: 0.0529\n",
      "Epoch [25/50], Step [96/96], Loss: 0.0001\n",
      "Epoch [26/50], Step [96/96], Loss: 0.0007\n",
      "Epoch [27/50], Step [96/96], Loss: 0.0003\n",
      "Epoch [28/50], Step [96/96], Loss: 0.0000\n",
      "Epoch [29/50], Step [96/96], Loss: 1.0811\n",
      "Epoch [30/50], Step [96/96], Loss: 1.2827\n",
      "Epoch [31/50], Step [96/96], Loss: 16.9654\n",
      "Epoch [32/50], Step [96/96], Loss: 8.5182\n",
      "Epoch [33/50], Step [96/96], Loss: 1.6858\n",
      "Epoch [34/50], Step [96/96], Loss: 0.1916\n",
      "Epoch [35/50], Step [96/96], Loss: 4.7504\n",
      "Epoch [36/50], Step [96/96], Loss: 2.6479\n",
      "Epoch [37/50], Step [96/96], Loss: 22.3590\n",
      "Epoch [38/50], Step [96/96], Loss: 0.3697\n",
      "Epoch [39/50], Step [96/96], Loss: 0.0404\n",
      "Epoch [40/50], Step [96/96], Loss: 0.0751\n",
      "Epoch [41/50], Step [96/96], Loss: 1.2874\n",
      "Epoch [42/50], Step [96/96], Loss: 0.0002\n",
      "Epoch [43/50], Step [96/96], Loss: 0.1868\n",
      "Epoch [44/50], Step [96/96], Loss: 0.0011\n",
      "Epoch [45/50], Step [96/96], Loss: 0.0010\n",
      "Epoch [46/50], Step [96/96], Loss: 0.0002\n",
      "Epoch [47/50], Step [96/96], Loss: 0.0005\n",
      "Epoch [48/50], Step [96/96], Loss: 0.0000\n",
      "Epoch [49/50], Step [96/96], Loss: 0.0002\n",
      "Epoch [50/50], Step [96/96], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "entrainement(dataloader_train_audio, input_size_audio, model_audio, optimizer_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement avec données mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [96/96], Loss: 1.4293\n",
      "Epoch [2/50], Step [96/96], Loss: 1.6098\n",
      "Epoch [3/50], Step [96/96], Loss: 1.2785\n",
      "Epoch [4/50], Step [96/96], Loss: 0.6334\n",
      "Epoch [5/50], Step [96/96], Loss: 0.7100\n",
      "Epoch [6/50], Step [96/96], Loss: 0.9965\n",
      "Epoch [7/50], Step [96/96], Loss: 0.9923\n",
      "Epoch [8/50], Step [96/96], Loss: 0.6913\n",
      "Epoch [9/50], Step [96/96], Loss: 0.4752\n",
      "Epoch [10/50], Step [96/96], Loss: 0.6693\n",
      "Epoch [11/50], Step [96/96], Loss: 0.2428\n",
      "Epoch [12/50], Step [96/96], Loss: 0.4259\n",
      "Epoch [13/50], Step [96/96], Loss: 0.8531\n",
      "Epoch [14/50], Step [96/96], Loss: 0.5511\n",
      "Epoch [15/50], Step [96/96], Loss: 0.6605\n",
      "Epoch [16/50], Step [96/96], Loss: 0.5988\n",
      "Epoch [17/50], Step [96/96], Loss: 0.4076\n",
      "Epoch [18/50], Step [96/96], Loss: 0.3253\n",
      "Epoch [19/50], Step [96/96], Loss: 0.2579\n",
      "Epoch [20/50], Step [96/96], Loss: 0.5281\n",
      "Epoch [21/50], Step [96/96], Loss: 0.2390\n",
      "Epoch [22/50], Step [96/96], Loss: 1.1968\n",
      "Epoch [23/50], Step [96/96], Loss: 0.2084\n",
      "Epoch [24/50], Step [96/96], Loss: 0.2530\n",
      "Epoch [25/50], Step [96/96], Loss: 0.5386\n",
      "Epoch [26/50], Step [96/96], Loss: 0.1862\n",
      "Epoch [27/50], Step [96/96], Loss: 0.5611\n",
      "Epoch [28/50], Step [96/96], Loss: 1.1335\n",
      "Epoch [29/50], Step [96/96], Loss: 0.8422\n",
      "Epoch [30/50], Step [96/96], Loss: 0.3937\n",
      "Epoch [31/50], Step [96/96], Loss: 0.1265\n",
      "Epoch [32/50], Step [96/96], Loss: 0.1692\n",
      "Epoch [33/50], Step [96/96], Loss: 0.3521\n",
      "Epoch [34/50], Step [96/96], Loss: 0.1515\n",
      "Epoch [35/50], Step [96/96], Loss: 0.2135\n",
      "Epoch [36/50], Step [96/96], Loss: 0.1490\n",
      "Epoch [37/50], Step [96/96], Loss: 0.5804\n",
      "Epoch [38/50], Step [96/96], Loss: 0.4292\n",
      "Epoch [39/50], Step [96/96], Loss: 0.3503\n",
      "Epoch [40/50], Step [96/96], Loss: 0.1433\n",
      "Epoch [41/50], Step [96/96], Loss: 0.5328\n",
      "Epoch [42/50], Step [96/96], Loss: 0.2718\n",
      "Epoch [43/50], Step [96/96], Loss: 0.3640\n",
      "Epoch [44/50], Step [96/96], Loss: 0.3012\n",
      "Epoch [45/50], Step [96/96], Loss: 0.2635\n",
      "Epoch [46/50], Step [96/96], Loss: 0.1758\n",
      "Epoch [47/50], Step [96/96], Loss: 0.3295\n",
      "Epoch [48/50], Step [96/96], Loss: 0.1769\n",
      "Epoch [49/50], Step [96/96], Loss: 0.1172\n",
      "Epoch [50/50], Step [96/96], Loss: 0.0460\n"
     ]
    }
   ],
   "source": [
    "entrainement(dataloader_train_mfcc, input_size_mfcc, model_mfcc, optimizer_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement avec données spectrogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [96/96], Loss: 4.6451\n",
      "Epoch [2/50], Step [96/96], Loss: 2.5878\n",
      "Epoch [3/50], Step [96/96], Loss: 0.8375\n",
      "Epoch [4/50], Step [96/96], Loss: 1.9509\n",
      "Epoch [5/50], Step [96/96], Loss: 1.8686\n",
      "Epoch [6/50], Step [96/96], Loss: 1.3487\n",
      "Epoch [7/50], Step [96/96], Loss: 1.7216\n",
      "Epoch [8/50], Step [96/96], Loss: 1.2764\n",
      "Epoch [9/50], Step [96/96], Loss: 0.5114\n",
      "Epoch [10/50], Step [96/96], Loss: 0.7608\n",
      "Epoch [11/50], Step [96/96], Loss: 0.7577\n",
      "Epoch [12/50], Step [96/96], Loss: 0.4584\n",
      "Epoch [13/50], Step [96/96], Loss: 0.8152\n",
      "Epoch [14/50], Step [96/96], Loss: 0.0803\n",
      "Epoch [15/50], Step [96/96], Loss: 0.1133\n",
      "Epoch [16/50], Step [96/96], Loss: 0.7850\n",
      "Epoch [17/50], Step [96/96], Loss: 1.8574\n",
      "Epoch [18/50], Step [96/96], Loss: 1.1781\n",
      "Epoch [19/50], Step [96/96], Loss: 0.8383\n",
      "Epoch [20/50], Step [96/96], Loss: 0.1288\n",
      "Epoch [21/50], Step [96/96], Loss: 0.8130\n",
      "Epoch [22/50], Step [96/96], Loss: 0.2895\n",
      "Epoch [23/50], Step [96/96], Loss: 1.5471\n",
      "Epoch [24/50], Step [96/96], Loss: 0.0286\n",
      "Epoch [25/50], Step [96/96], Loss: 0.3811\n",
      "Epoch [26/50], Step [96/96], Loss: 0.4344\n",
      "Epoch [27/50], Step [96/96], Loss: 0.5347\n",
      "Epoch [28/50], Step [96/96], Loss: 0.4053\n",
      "Epoch [29/50], Step [96/96], Loss: 0.3781\n",
      "Epoch [30/50], Step [96/96], Loss: 0.1396\n",
      "Epoch [31/50], Step [96/96], Loss: 0.2816\n",
      "Epoch [32/50], Step [96/96], Loss: 0.0666\n",
      "Epoch [33/50], Step [96/96], Loss: 0.0541\n",
      "Epoch [34/50], Step [96/96], Loss: 0.3320\n",
      "Epoch [35/50], Step [96/96], Loss: 0.7446\n",
      "Epoch [36/50], Step [96/96], Loss: 0.1940\n",
      "Epoch [37/50], Step [96/96], Loss: 0.6932\n",
      "Epoch [38/50], Step [96/96], Loss: 0.0450\n",
      "Epoch [39/50], Step [96/96], Loss: 0.0440\n",
      "Epoch [40/50], Step [96/96], Loss: 0.1883\n",
      "Epoch [41/50], Step [96/96], Loss: 0.2091\n",
      "Epoch [42/50], Step [96/96], Loss: 0.1653\n",
      "Epoch [43/50], Step [96/96], Loss: 0.0650\n",
      "Epoch [44/50], Step [96/96], Loss: 0.1603\n",
      "Epoch [45/50], Step [96/96], Loss: 0.0811\n",
      "Epoch [46/50], Step [96/96], Loss: 0.5913\n",
      "Epoch [47/50], Step [96/96], Loss: 0.1185\n",
      "Epoch [48/50], Step [96/96], Loss: 0.0881\n",
      "Epoch [49/50], Step [96/96], Loss: 0.1673\n",
      "Epoch [50/50], Step [96/96], Loss: 0.2205\n"
     ]
    }
   ],
   "source": [
    "entrainement(dataloader_train_spect, input_size_spect, model_spect, optimizer_spect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créer une fonction qui nous permet de tester nos réseaux pour les différents types de données que nous avons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, model, input_size, data_type):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_data = 0\n",
    "    \n",
    "        for images, labels in dataset:\n",
    "            images = images.float()\n",
    "            images = images.reshape(-1, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "\n",
    "\n",
    "            # Conversion des probabilités en prédictions binaires (0 ou 1)\n",
    "            predictions = torch.argmax(probabilities)\n",
    "        \n",
    "    \n",
    "            # Comparaison des prédictions avec les labels pour calculer la précision\n",
    "            n_correct += (predictions == labels).sum().item()\n",
    "            n_data += labels.size(0)\n",
    "        acc = 100*  n_correct / n_data\n",
    "        \n",
    "        print(f'Précision du réseau pour la prédiction du chiffre prononcé avec approche', data_type, ':', acc, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A présent on test nos modèles et on calcule leurs précisions pour la classification de nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance des réseaux pour nos différentes approches :\n",
      "Précision du réseau pour la prédiction du chiffre prononcé avec approche audio : 23.0 %\n",
      "Précision du réseau pour la prédiction du chiffre prononcé avec approche mfcc : 89.83333333333333 %\n",
      "Précision du réseau pour la prédiction du chiffre prononcé avec approche spectrogramme : 88.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "print('Performance des réseaux pour nos différentes approches :')\n",
    "test(dataloader_test_audio, model_audio, input_size_audio, \"audio\")\n",
    "test(dataloader_test_mfcc, model_mfcc, input_size_mfcc, \"mfcc\")\n",
    "test(dataloader_test_spect, model_spect, input_size_spect, \"spectrogramme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Nous avons tester différentes approches pour la classification de signaux audios.\n",
    "\n",
    "##### Vecteurs audios \n",
    "\n",
    "Nous obtenons une précision de 20.1% en utilisant les vecteurs audios. On en conclu qu'il n'y a aucune généralisation pour cette approche. En effet nous avons 10 classes donc pour un réseau aléatoire on obtiendrait envion 10%. L'approche des vecteurs audio n'est donc pas fonctionnelle pour la classification de signaux audios.\n",
    "\n",
    "##### Coefficients MFCC\n",
    "\n",
    "Nous obtenons une précision de 89.83% en utilisant les coefficient MFCC. Ceci est un taux de précision très intérressant qui traduit une bonne généralisation sur l'ensemble de test de notre dataset. De plus les vecteur utilisés pour cette approche sont de petite taille (20) ainsi l'entrainement est très rapide pour 50 epochs. Nous pourrions aisément essayer d'entrainer sur plus d'epochs notre réseau pour essayer d'atteindre une précision encore meilleure. \n",
    "\n",
    "##### Spectrogrammes \n",
    "\n",
    "Nous obtenons de bons résultats avec cette approche avec un taux de 88.6%. Cela est un très bon taux et traduit une très bonne généralisation de notre modèle sur notre ensemble de test. Pour cette approche l'entrainement à cependant nécessité plus de ressources et donc plus de temps car nos données d'entrée sont des vecteurs de taille 64x64x4. Aussi cette approche revient à de la computer vision puisqu'on utilise l'image de nos spectrogrammes. Ainsi on peut penser qu'en utilisant un réseau de convolution on pourrait obtenir de meilleurs résultats.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_TP3_ift780",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
